{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "import sys\n",
    "import tweepy\n",
    "import igraph\n",
    "#import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import ast\n",
    "import operator\n",
    "#from igraph import *\n",
    "import re\n",
    "#from karateclub import Graph2Vec\n",
    "#import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetProcessor():\n",
    "    '''\n",
    "    A wrapper class for Tweepy.\n",
    "    Fetches data with tweepy, preprocesses it and saves it as csv.\n",
    "    Allows search with a keyword or a username.\n",
    "    '''\n",
    "    def __init__(self, api_key, api_secret, access_token, access_secret):\n",
    "        self.auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "        self.auth.set_access_token(access_token, access_secret)\n",
    "        self.api = tweepy.API(self.auth)\n",
    "        \n",
    "    def strip_non_ascii(self, string):\n",
    "        '''Returns a string without the non-ascii characters'''\n",
    "        stripped = (char for char in string if 0 < ord(char) < 127)\n",
    "        return ''.join(stripped)\n",
    "\n",
    "    def write_csv(self, prefix, api_response):\n",
    "        '''Writes a csv file based on a given api response'''\n",
    "        fieldnames = [\n",
    "            'tweet_id', 'tweet_text', 'date', 'user_id',\n",
    "            'follower_count','retweet_count','user_mentions'\n",
    "        ]\n",
    "        with open(f'./data/{prefix.lower()}_tweets.csv', 'w', newline = '') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames = fieldnames)\n",
    "            writer.writeheader()\n",
    "            for tweet in tqdm(api_response):\n",
    "                text = self.strip_non_ascii(tweet.full_text)\n",
    "                date = tweet.created_at.strftime('%m/%d/%Y')        \n",
    "                writer.writerow({\n",
    "                    'tweet_id': tweet.id_str,\n",
    "                    'tweet_text': text,\n",
    "                    'date': date,\n",
    "                    'user_id': tweet.user.id_str,\n",
    "                    'follower_count': tweet.user.followers_count,\n",
    "                    'retweet_count': tweet.retweet_count,\n",
    "                    'user_mentions': tweet.entities['user_mentions']\n",
    "                })\n",
    "\n",
    "    def keyword_search(self, keyword):\n",
    "        '''Fetches tweets based on the presence of a keyword'''\n",
    "        api_response = self.api.search(\n",
    "            q = keyword,\n",
    "            rpp = 1000,\n",
    "            show_user = True,\n",
    "            tweet_mode = 'extended'\n",
    "        )\n",
    "        self.write_csv(keyword, api_response)\n",
    "        \n",
    "    def user_search(self, user):\n",
    "        '''Fetches tweets of a given user'''\n",
    "        api_response = tweepy.Cursor(\n",
    "            self.api.user_timeline,\n",
    "            id = user,\n",
    "            tweet_mode = 'extended'\n",
    "        )\n",
    "        self.write_csv(user, api_response.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = TweetProcessor(\n",
    "    api_key = os.getenv('API_KEY'),\n",
    "    api_secret = os.getenv('API_SECRET'),\n",
    "    access_token = os.getenv('ACCESS_TOKEN'),\n",
    "    access_secret = os.getenv('ACCESS_SECRET')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "3218it [01:24, 38.27it/s]\n"
    }
   ],
   "source": [
    "processor.user_search(user = 'elonmusk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              tweet_id                                         tweet_text  \\\n0  1299646174874329088                           @EvaFoxU @waitbutwhy Yup   \n1  1299641513450721280  @PPathole @ID_AA_Carmack Actually C, although ...   \n2  1299633884129193984  @ID_AA_Carmack I like C, because it avoids cla...   \n\n         date   user_id  follower_count  retweet_count  \\\n0  08/29/2020  44196397        38336776             24   \n1  08/29/2020  44196397        38336776             38   \n2  08/29/2020  44196397        38336776             87   \n\n                                       user_mentions  \n0  [{'screen_name': 'EvaFoxU', 'name': 'Eva Fox ðŸ¦Š...  \n1  [{'screen_name': 'PPathole', 'name': 'Pranay P...  \n2  [{'screen_name': 'ID_AA_Carmack', 'name': 'Joh...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>tweet_text</th>\n      <th>date</th>\n      <th>user_id</th>\n      <th>follower_count</th>\n      <th>retweet_count</th>\n      <th>user_mentions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1299646174874329088</td>\n      <td>@EvaFoxU @waitbutwhy Yup</td>\n      <td>08/29/2020</td>\n      <td>44196397</td>\n      <td>38336776</td>\n      <td>24</td>\n      <td>[{'screen_name': 'EvaFoxU', 'name': 'Eva Fox ðŸ¦Š...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1299641513450721280</td>\n      <td>@PPathole @ID_AA_Carmack Actually C, although ...</td>\n      <td>08/29/2020</td>\n      <td>44196397</td>\n      <td>38336776</td>\n      <td>38</td>\n      <td>[{'screen_name': 'PPathole', 'name': 'Pranay P...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1299633884129193984</td>\n      <td>@ID_AA_Carmack I like C, because it avoids cla...</td>\n      <td>08/29/2020</td>\n      <td>44196397</td>\n      <td>38336776</td>\n      <td>87</td>\n      <td>[{'screen_name': 'ID_AA_Carmack', 'name': 'Joh...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "elonmusk_tweets = pd.read_csv('./data/elonmusk_tweets.csv')\n",
    "\n",
    "elonmusk_tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"[{'screen_name': 'PPathole', 'name': 'Pranay Pathole', 'id': 1291945442, 'id_str': '1291945442', 'indices': [0, 9]}, {'screen_name': 'ID_AA_Carmack', 'name': 'John Carmack', 'id': 175624200, 'id_str': '175624200', 'indices': [10, 24]}]\""
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "elonmusk_tweets.loc[1, 'user_mentions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetweetParser():\n",
    "    '''\n",
    "    A class for parsing data from a tweets csv file.\n",
    "    Creates an edge list in the class attribute edge_list.\n",
    "    '''\n",
    "    def __init__(self, data, user):\n",
    "        self.data = data\n",
    "        self.user = user\n",
    "        self.edge_list = []\n",
    "\n",
    "    def write_csv(self, prefix):\n",
    "        '''\n",
    "        Writes a csv file based on the created edge list.\n",
    "        The format is from - to - edge weight.\n",
    "        '''\n",
    "        df = pd.DataFrame(parser.edge_list)\n",
    "        df.columns = ['from_user', 'to_user', 'log_retweet']\n",
    "        df.to_csv(f'./data/{prefix.lower()}_tweets_edges.csv', index = False)\n",
    "  \n",
    "    def create_graph(self):\n",
    "        '''\n",
    "        Constructs the edge list of an undirected graph\n",
    "        for tweets and the user mentions of the tweets.\n",
    "        Edge weights are based on retweet count.\n",
    "        '''\n",
    "        for _, row in tqdm(self.data.iterrows()):\n",
    "            user_mentions = ast.literal_eval(row[6])\n",
    "            num_user_mentions = len(user_mentions)\n",
    "            # if tweet contains user mentions\n",
    "            if num_user_mentions > 0:\n",
    "                num_retweets = row[5]\n",
    "                edge_weight = np.log(num_retweets + 1)\n",
    "                # iterate over all user mentions of a single tweet \n",
    "                for i, mention in enumerate(user_mentions):\n",
    "                    # add to edge list (tweet user, tweet mention, weight)\n",
    "                    from_user = self.user\n",
    "                    to_user = mention['screen_name']\n",
    "                    self.edge_list.append((from_user, to_user, edge_weight))\n",
    "                    # also create single edge between all that were mentioned\n",
    "                    for j in range(i+1, num_user_mentions):\n",
    "                        from_user = user_mentions[i]['screen_name']\n",
    "                        to_user = user_mentions[j]['screen_name']\n",
    "                        self.edge_list.append((from_user, to_user, edge_weight))\n",
    "\n",
    "        self.write_csv(self.user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "3218it [00:00, 6898.22it/s]\n"
    }
   ],
   "source": [
    "parser = RetweetParser(elonmusk_tweets, 'elonmusk')\n",
    "\n",
    "parser.create_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  from_user        to_user  log_retweet\n0  elonmusk        EvaFoxU     3.218876\n1   EvaFoxU     waitbutwhy     3.218876\n2  elonmusk     waitbutwhy     3.218876\n3  elonmusk       PPathole     3.663562\n4  PPathole  ID_AA_Carmack     3.663562",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>from_user</th>\n      <th>to_user</th>\n      <th>log_retweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>elonmusk</td>\n      <td>EvaFoxU</td>\n      <td>3.218876</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>EvaFoxU</td>\n      <td>waitbutwhy</td>\n      <td>3.218876</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>elonmusk</td>\n      <td>waitbutwhy</td>\n      <td>3.218876</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>elonmusk</td>\n      <td>PPathole</td>\n      <td>3.663562</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PPathole</td>\n      <td>ID_AA_Carmack</td>\n      <td>3.663562</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "elonmusk_edges = pd.read_csv('./data/elonmusk_tweets_edges.csv')\n",
    "\n",
    "elonmusk_edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In graph theory, eigenvector centrality is a measure of the influence of a node in a network. Relative scores are assigned to all nodes in the network based on the concept that connections to high-scoring nodes contribute more to the score of the node in question than equal connections to low-scoring nodes. A high eigenvector score means that a node is connected to many nodes who themselves have high scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetGraph():\n",
    "    '''\n",
    "    Creates an undirected graph based on the given edge list.\n",
    "    Computes eigenvector centralities of users and returns those\n",
    "    as a sorted list.\n",
    "    '''\n",
    "    def __init__(self, edge_list):\n",
    "        self.edges = edge_list.to_records(index = False)\n",
    "        self.graph = igraph.Graph.TupleList(self.edges, weights = True, directed = False)\n",
    "        \n",
    "    def eigen_centrality(self):\n",
    "        vectors = self.graph.eigenvector_centrality()\n",
    "        e = {name:c for c, name in zip([v for v in vectors], self.graph.vs['name'])}\n",
    "        sorted_centralities = sorted(e.items(), key = operator.itemgetter(1),reverse = True)\n",
    "        return sorted_centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('elonmusk', 1.0),\n ('flcnhvy', 0.443292665702936),\n ('Erdayastronaut', 0.43008177534026504),\n ('Tesla', 0.3935513697220432),\n ('SpaceX', 0.39163650190775473),\n ('PPathole', 0.2843011938425921),\n ('thirdrowtesla', 0.252332971886585),\n ('teslaownersSV', 0.2114131920965722),\n ('Teslarati', 0.18420633805959424),\n ('Kristennetten', 0.16062698473854248),\n ('NASA', 0.1580533805394101),\n ('SciGuySpace', 0.15137290023458402),\n ('RationalEtienne', 0.12873626168977528),\n ('cleantechnica', 0.1251335549009306),\n ('NASASpaceflight', 0.12313385624003266),\n ('vincent13031925', 0.11006763928045547),\n ('EvaFoxU', 0.098561668947237),\n ('Space_Station', 0.09189871849586237),\n ('28delayslater', 0.08417590419790916),\n ('AstroBehnken', 0.07417416478291959)]"
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "elonmusk_graph = TweetGraph(elonmusk_edges)\n",
    "\n",
    "elonmusk_graph.eigen_centrality()[:20]"
   ]
  }
 ]
}